---
layout: cv
title: Antoine HAMON CV
---

# Antoine HAMON
Data Scientist at Lincoln

<div id="webaddress">
    <a href="mailto:antoine.hamon22@gmail.com"><i class="far fa-envelope"></i> Mail</a>
    | <a href="https://github.com/ZwAnto"><i class="fab fa-github"></i> GitHub</a>
    | <a href="https://www.linkedin.com/in/hamonantoine/"><i class="fab fa-linkedin"></i> LinkedIn</a>
</div>

## Experiences

`2016 - now`
__Data Scientist__ *Lincoln, Ile-de-France*  

Data Science consultant 
Consultant sur des problématiques liées à l'analyse et au traitement de la donnée.
* Proeficient in R and Python and basic knowledge in SAS
* Regular use of different machin learning methods/algorithms (PLS regression, Lasso/Ridge regression, ACP, Fourier Series)
* Shiny development (dashboard, applications) alongside with HTML/CSS and JavaScript
* R trainer for lincoln client

{::options parse_block_html="true" /}
<div class='sub_container'>
__Servier__ `2019 - now`  
Projets de text-mining/NLP sur des données issues de scraping (forums, publications médicales).  
Traitement d'images avec des techniques issues du Deep Learning sur des données publiques (arthrose, retinopathie diabétique).
    
Technologies : R, Python, Spacy, Tensorflow
    
__Carrefour__ `2017 - 2019`  

While working for CSA Data Consulting, I had the opportunity to work at Carrefour's french headquarter in Massy. The objective was to deliver to Carrefour a tool to analyze the performance of past media-marketing campaign and provide insight on how to drive their future media investments. 

__CSA Data Consulting__ `2016 - 2019`  
Implementation of marketing mix modelling analysis in order to evaluate the impact of different factors (media investments, CRM, discounts ...) on business indicator. 
Providing insight and advice base on the results of our analysis to drive the future media marketing campaign for CSA DC's clients (B2B).

* Data cleaning/wrangling
* Building structured databases
* Marketing Mix Modelling implementation using well known algorithm (OLS/PLS regression, Elasticnet)
* Building data visualisation/simulation application containing:
    - Basic statistics on past media investments
    - MMM results
    - Insights/Advices and simulation tool for future media marketing campaigns

Technologies : SAS, R, R Shiny, HTML/CSS, JavaScript  
Methods : OLS/PLS regression, fourrier series
</div>

`2016`
__Geomarketing and Statistic Intership__ *SoLocal Group - Pages Jaunes, Ile-de-France*  
I was working for the datamining team of a marketing department. The objective of my internship was to developp a tool to detect sales opportunities on SEA/search product for the PagesJaunes search engine.  
The opportunities were identified by taking into account, for a given professional, all the competitors in his geographic area/business, the actual volume of search queries made by potential clients and the search product currently sold to competitors.
After an atemp to build a tool using excel/VBA and SAS, I finally choose to build a shiny application. The application allow the sales force to search for a given professionals (either client or prospect) to get all the search product for which he might have an interest in order to improve his visibility.

Technologies : R, SAS, QGIS, JavaScript, Leaflet.js, Visual Basic, Excel

## Projets

__Challenges Data Science Lincoln__  
Internal data science challenge organize by Lincoln on various subjects from data visualisation to deep learning. Those challenges are an opportunity to improve and developp new programming skills and to learn novel machin learning methods/algorithms (deep learning, NLP, ...).

{::options parse_block_html="true" /}
<div class='sub_container'>
__Twitter et JO 2024__  
Traitement et nettoyage des tweets avec des techniques issues du NLP. Mon approche à été d'identifier des semaines voisines relativement similaires en terme de thématique afin d'identifier les différents évènements survenus durant la période de candidature de Paris aux JO 2024. Creation d'une application web connectée à un cluster Elastic pour la restitution.  
Technologies : Python, HTML/CSS, ElasticSearch  
Méthodes : Bag-of-Words, TF-IDF, T-SNE, DBSCAN  

__Dataviz - La propreté à Paris__  
Création d'un dashboard sur la thématique de la propreté à Paris.  
Lien vers le dashbaord <a href='https://zwanto.org/lincoln/'><i class="fas fa-external-link-alt"></i></a>  
Technologies : HTML/CSS, Highcharts.hs, Leaflet.js  

__Reconnaissance d'image CIFAR-10__  
Deep Learning sur le jeux de données CIFAR-10. Réimplémentation des différentes couches d'un réseaux à convolutions sous Python avec numpy.  
Creation d'une webapp avec Django. L'utilisateur dessine un chiffre et l'application renvoi le chiffre qui à été dessiné en se basant sur un réseux de neurones entrainé sur MNIST.  
GitHub repo <a href='https://github.com/Zwanto/pynet/'><i class="fas fa-external-link-alt"></i></a>  
Technologies : Python, Django, Docker  
Méthodes : CNN, RNN  

__Kaggle - House Prices: Advanced Regression Techniques__  
</div>

__Projets personnels__  

{::options parse_block_html="true" /}
<div class='sub_container'>
    
__Apprentissage par renforcement__  
Utitisation de Deep Q neural network pour entrainer un agent sur des environnements Atari 2600 (Space Invaders).  
Technologies : Python, Keras, OpenAI Gym  
Méthodes : Autoencoder, CNN, DQN  

__Web scrapping__  
Scrapping de sites bancaires avec Python pour récupérer les opérations sur comptes bancaires.  
L'idée est de pouvoir alimenter une application web de gestion budgetaire.


__Application gestion budgétaire__  
Développement d'une application web de suivi des dépenses.  
Technologies : HTML/CSS, Javascript, PHP, SQL
</div>


## Compétences techniques {#technical-skills}

R  
Shiny  
Python  
Tensorflow  
Keras  
Markdown  
SAS  
SQL  
HTML/CSS  
JavaScript  
Docker  
Git  

## Education

`2015-16`
__Master 2 Statistiques - Économétrie__ spécialité prévision risque et marché  
*Université Rennes I*  
Économétrie spatiale, datamining, scoring, Big Data.
* Projet de segmentation client dans le domaine de lʼassurance (classification, clustering, analyse discriminante) réalisé sous SAS
* Projet « trieur de spam » réalisé à lʼaide dʼoutils issue du Machine Learning (forêt aléatoire, svm, réseaux de neurones) sous R

`2014-15`
__Master 1 Statistique - Économétrie__  
*Université Rennes I*  
Econométrie, analyse des données (analyse en composante principale, analyse des correspondances, classification), théorie des jeux, économie de lʼincertain.

`2011-14`
__Licence Mathématique - Économie__  
*Université Rennes I*  
Econométrie quantitative, statistiques mathématiques, probabilités,
macroéconomie, microéconomie
